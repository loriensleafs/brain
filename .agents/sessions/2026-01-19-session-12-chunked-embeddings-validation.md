# Session Log: Chunked Embeddings Implementation Validation

**Date**: 2026-01-19
**Session**: 12
**Agent**: QA
**Branch**: main
**Starting Commit**: ccc2ab4

## Objective

Validate the chunked embeddings implementation works correctly across:

- TypeScript compilation
- Embedding generation (including long notes)
- Search functionality with deduplication
- Chunk metadata storage

## Approach

Following validation steps provided:

1. TypeScript compilation check
2. Clear old embeddings (schema migration)
3. Test embedding generation with limit
4. Test search with deduplication
5. Verify long note handling

## Session Start Checklist

- [x] Branch verified (main)
- [x] Starting commit noted (ccc2ab4)
- [x] Session log created
- [ ] Brain MCP initialized
- [ ] Previous context reviewed

## Validation Results

### Step 1: TypeScript Compilation

**Command**: `cd /Users/peter.kloss/Dev/brain/apps/mcp && bun run tsc --noEmit`

**Status**: [PASS]
**Result**: No compilation errors

### Step 2: Schema Migration

**Status**: [PASS]
**Result**: Old table dropped, new chunked schema created successfully
**Evidence**: Migration script completed, 28 embeddings stored with chunk metadata

### Step 3: Embedding Generation Test

**Command**: `./apps/tui/brain embed --project brain --limit 50`

**Status**: [PARTIAL PASS]
**Result**: 21/50 processed, 29 failed with Ollama 500 errors
**Evidence**:

- Successfully embedded notes: 28 total (all single-chunk)
- Failed notes consistently hitting Ollama API 500 errors
- Issue is NOT with chunking implementation - appears to be Ollama resource/rate limiting

### Step 4: Search Test

**Command**: `./apps/tui/brain search --project brain "session protocol" --mode semantic`

**Status**: [FAIL - BLOCKING BUG]
**Result**: Zero results returned even with 28 embeddings and threshold 0.01
**Root Cause**: SQL query bug in `semanticSearchChunked` function

### Step 5: Long Note Handling

**Status**: [UNABLE TO TEST]
**Reason**: All successfully embedded notes are short (single-chunk). Long notes failing with Ollama 500 before chunking logic is reached.

## Issues Found

### P0: Semantic Search Non-Functional

**File**: `apps/mcp/src/db/vectors.ts` lines 213-226
**Issue**: SQL syntax error - WHERE clause references SELECT alias

```typescript
SELECT
  chunk_id,
  entity_id,
  vec_distance_cosine(embedding, ?) as distance
FROM brain_embeddings
WHERE distance <= ?  -- âŒ Cannot reference alias from SELECT
```

**Impact**: Semantic search returns zero results for all queries
**Evidence**:

- Direct SQL tests confirm WHERE clause with alias fails
- Removing WHERE clause returns results
- COUNT(*) with subquery works

**Fix Required**: Rewrite query to use subquery or inline distance calculation in WHERE clause

### P1: Ollama 500 Errors During Embedding Generation

**Scope**: Affects ~58% of notes (29/50 in test batch)
**Symptoms**:

- Consistent Ollama API 500 errors
- Not related to note length (failing notes include both short and long)
- Prevents full embedding coverage

**Evidence**:

- Ollama is running and responds to direct API calls
- Same model works for query embeddings
- Errors occur during batch processing

**Possible Causes**:

1. Rate limiting (100ms delay between calls may be insufficient)
2. Memory/resource exhaustion
3. Request payload issues

**Recommended Investigation**:

1. Check Ollama logs for specific error messages
2. Test with longer delays between requests
3. Test with smaller batch sizes

### P2: Unable to Validate Chunking for Long Notes

**Reason**: No long notes successfully embedded yet
**Impact**: Cannot verify chunking works correctly for notes >2000 chars
**Recommendation**: Fix P0 and P1, then re-run with focus on long notes

## Recommendations

### Immediate Actions (Block PR)

1. **Fix P0 semantic search bug** - Rewrite query in `semanticSearchChunked`:

   ```sql
   -- Option 1: Subquery
   SELECT * FROM (
     SELECT chunk_id, entity_id, vec_distance_cosine(embedding, ?) as distance
     FROM brain_embeddings
   ) WHERE distance <= ?

   -- Option 2: Inline calculation
   SELECT chunk_id, entity_id, vec_distance_cosine(embedding, ?) as distance
   FROM brain_embeddings
   WHERE vec_distance_cosine(embedding, ?) <= ?
   ```

2. **Add integration test** for semantic search to catch this in CI
3. **Investigate Ollama 500 errors** before claiming chunking validation complete

### Follow-Up Actions

1. Generate embeddings for all notes once Ollama issues resolved
2. Validate chunking with known long notes (>2000 chars)
3. Verify deduplication works correctly when notes have multiple chunks
4. Performance test with larger corpus

## Verdict

**Status**: [BLOCKED]
**Confidence**: High
**Rationale**: Critical bug in semantic search makes feature non-functional. Chunking implementation appears correct (TypeScript compiles, schema migrated successfully), but cannot be validated until search works.

## Session End Checklist

- [x] All validation steps completed
- [x] Test report created (`.agents/qa/003-chunked-embeddings-validation-report.md`)
- [x] Issues documented (P0, P1, P2 in report)
- [x] Markdown linted
- [ ] Changes committed (git commit blocked - user must commit manually)
- [ ] Brain memory updated
- [ ] Session protocol validated

## Evidence

| Requirement | Evidence |
|-------------|----------|
| Validation executed | Commands run, outputs captured |
| Schema migration | `migrate-embeddings.ts` successful |
| Search bug identified | Test scripts demonstrate SQL issue |
| Test report saved | `.agents/qa/003-chunked-embeddings-validation-report.md` |
